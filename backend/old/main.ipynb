{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internet imports\n",
    "import os\n",
    "import datetime\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user imports\n",
    "import windowGenarator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Chatgpt Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#########################################\n",
    "# Configuration\n",
    "#########################################\n",
    "\n",
    "num_stations = 5\n",
    "features_per_station = 12  # Example; adjust to actual feature count\n",
    "input_width = 24           # Example\n",
    "label_width = 1\n",
    "shift = 1\n",
    "label_columns = [\"TD (degC)\"]\n",
    "target_station_idx = 0\n",
    "\n",
    "# Model hyperparameters\n",
    "cnn_out_dim = 32\n",
    "d_model = 64\n",
    "num_heads = 4\n",
    "num_station_transformer_layers = 2\n",
    "num_time_transformer_layers = 2\n",
    "\n",
    "#########################################\n",
    "# Load Data and Coordinates\n",
    "#########################################\n",
    "# Assume these DataFrames and station_coords are already loaded and preprocessed\n",
    "# train_df, val_df, test_df = ...\n",
    "# station_coords_df = pd.read_csv('stations_coords.csv')\n",
    "# Sort by station_id and extract coords in order\n",
    "# station_coords = station_coords_df[['x', 'y']].values.astype(np.float32)\n",
    "# Normalize coords if needed\n",
    "\n",
    "station_coords = np.array([\n",
    "    [350000, 3200000],\n",
    "    [351000, 3201000],\n",
    "    [352000, 3202000],\n",
    "    [353000, 3203000],\n",
    "    [354000, 3204000]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Optional: normalize coordinates\n",
    "# x_min, x_max = station_coords[:,0].min(), station_coords[:,0].max()\n",
    "# y_min, y_max = station_coords[:,1].min(), station_coords[:,1].max()\n",
    "# station_coords[:,0] = (station_coords[:,0] - x_min)/(x_max - x_min)\n",
    "# station_coords[:,1] = (station_coords[:,1] - y_min)/(y_max - y_min)\n",
    "\n",
    "#########################################\n",
    "# WindowGenerator (Given by you)\n",
    "#########################################\n",
    "# window = WindowGenerator(input_width=input_width,\n",
    "#                          label_width=label_width,\n",
    "#                          shift=shift,\n",
    "#                          train_df=train_df,\n",
    "#                          val_df=val_df,\n",
    "#                          test_df=test_df,\n",
    "#                          label_columns=label_columns)\n",
    "\n",
    "#########################################\n",
    "# Model Components\n",
    "#########################################\n",
    "\n",
    "def make_station_cnn(features_per_station, cnn_out_dim):\n",
    "    \"\"\"\n",
    "    CNN that processes a single station's time series of shape (batch, input_width, features_per_station).\n",
    "    We'll keep the time dimension. The output shape: (batch, input_width, cnn_out_dim)\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv1D(filters=32, kernel_size=3, padding='causal', activation='relu', input_shape=(input_width, features_per_station)),\n",
    "        layers.Conv1D(filters=32, kernel_size=3, padding='causal', activation='relu'),\n",
    "        # No pooling here, we keep the time dimension\n",
    "        layers.Dense(cnn_out_dim)  # map to cnn_out_dim\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "class TransformerEncoderLayer(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential([\n",
    "            layers.Dense(dff, activation='relu'),\n",
    "            layers.Dense(d_model),\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        # x: (batch, seq_len, d_model)\n",
    "        attn_output = self.mha(x, x, training=training)  # Self-attention\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.enc_layers = [TransformerEncoderLayer(d_model, num_heads, dff, dropout) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training=training)\n",
    "        return x\n",
    "\n",
    "class MultiStationModel(keras.Model):\n",
    "    def __init__(self, \n",
    "                 num_stations, \n",
    "                 features_per_station,\n",
    "                 station_coords, \n",
    "                 cnn_out_dim,\n",
    "                 d_model,\n",
    "                 num_station_transformer_layers,\n",
    "                 num_time_transformer_layers,\n",
    "                 num_heads,\n",
    "                 target_station_idx=0,\n",
    "                 label_width=1):\n",
    "        super().__init__()\n",
    "        self.num_stations = num_stations\n",
    "        self.features_per_station = features_per_station\n",
    "        self.target_station_idx = target_station_idx\n",
    "        self.label_width = label_width\n",
    "        self.station_coords = tf.constant(station_coords, dtype=tf.float32) # (num_stations, 2)\n",
    "\n",
    "        # A CNN for each station:\n",
    "        # We'll apply the same CNN weights to all stations (shared weights)\n",
    "        # If you need distinct CNNs per station, create a list of CNNs.\n",
    "        self.station_cnn = make_station_cnn(features_per_station, cnn_out_dim)\n",
    "\n",
    "        # Project CNN output + coords to d_model\n",
    "        self.project = layers.Dense(d_model)\n",
    "\n",
    "        # Transformer for station dimension\n",
    "        self.station_transformer = TransformerEncoder(num_station_transformer_layers, d_model, num_heads)\n",
    "\n",
    "        # Transformer for time dimension (long-term patterns)\n",
    "        self.time_transformer = TransformerEncoder(num_time_transformer_layers, d_model, num_heads)\n",
    "\n",
    "        # Final output layer\n",
    "        self.output_layer = layers.Dense(self.label_width)  # Predict 1 step (or label_width steps)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        # inputs: (batch, input_width, total_features)\n",
    "        # total_features = num_stations * features_per_station\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        total_features = self.num_stations * self.features_per_station\n",
    "        # Split the input for each station\n",
    "        # Shape: (batch, input_width, features_per_station) per station\n",
    "        station_embeddings_list = []\n",
    "        for i in range(self.num_stations):\n",
    "            start = i * self.features_per_station\n",
    "            end = start + self.features_per_station\n",
    "            station_data = inputs[:, :, start:end]  # (batch, input_width, features_per_station)\n",
    "            \n",
    "            # CNN to extract local patterns\n",
    "            station_cnn_out = self.station_cnn(station_data, training=training) # (batch, input_width, cnn_out_dim)\n",
    "            \n",
    "            # Add coordinates (x, y) to each time step\n",
    "            # coords shape: (1, 1, 2) expanded to (batch, input_width, 2)\n",
    "            coords = tf.reshape(self.station_coords[i], (1,1,2))\n",
    "            coords = tf.tile(coords, [batch_size, tf.shape(station_cnn_out)[1], 1]) # (batch, input_width, 2)\n",
    "            \n",
    "            # Concatenate coords\n",
    "            combined = tf.concat([station_cnn_out, coords], axis=-1) # (batch, input_width, cnn_out_dim+2)\n",
    "            \n",
    "            # Project to d_model\n",
    "            projected = self.project(combined, training=training) # (batch, input_width, d_model)\n",
    "            station_embeddings_list.append(projected)\n",
    "\n",
    "        # Now we have a list of station embeddings: each (batch, input_width, d_model)\n",
    "        # Stack them to form (batch, input_width, num_stations, d_model)\n",
    "        station_embeddings = tf.stack(station_embeddings_list, axis=2) # (batch, input_width, num_stations, d_model)\n",
    "\n",
    "        # First Transformer: Station dimension\n",
    "        # We want to understand station relationships at each time step.\n",
    "        # So for each time step t, we have (batch, num_stations, d_model).\n",
    "        # We'll flatten batch and time steps to process them at once:\n",
    "        \n",
    "        B = batch_size\n",
    "        T = input_width\n",
    "        S = self.num_stations\n",
    "\n",
    "        # Reshape to (B*T, S, d_model)\n",
    "        station_embeddings_reshaped = tf.reshape(station_embeddings, (B*T, S, d_model))\n",
    "        \n",
    "        # Pass through station-transformer\n",
    "        station_transformed = self.station_transformer(station_embeddings_reshaped, training=training) # (B*T, S, d_model)\n",
    "\n",
    "        # Extract target station embedding: (B*T, d_model)\n",
    "        target_embeddings = station_transformed[:, self.target_station_idx, :] # (B*T, d_model)\n",
    "\n",
    "        # Reshape back to (B, T, d_model)\n",
    "        target_time_series = tf.reshape(target_embeddings, (B, T, d_model))\n",
    "\n",
    "        # Second Transformer: Time dimension\n",
    "        # Now we model long-term temporal patterns of the target station embedding sequence.\n",
    "        # Shape: (batch, input_width, d_model)\n",
    "        time_transformed = self.time_transformer(target_time_series, training=training) # (batch, input_width, d_model)\n",
    "\n",
    "        # Predict temperature at the forecast horizon\n",
    "        # Assume we want the last time step embedding for prediction, or entire sequence if label_width > 1\n",
    "        # Since label_width=1, we take the last time step (e.g. final embedding)\n",
    "        final_embedding = time_transformed[:, -1, :] # (batch, d_model)\n",
    "        \n",
    "        predictions = self.output_layer(final_embedding) # (batch, label_width)\n",
    "        # Expand dims to (batch, label_width, 1) if needed\n",
    "        predictions = tf.expand_dims(predictions, -1) # (batch, label_width, 1)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "#########################################\n",
    "# Training Example\n",
    "#########################################\n",
    "\n",
    "# Example usage (uncomment and adjust once you have train/val/test data):\n",
    "# model = MultiStationModel(num_stations=num_stations,\n",
    "#                           features_per_station=features_per_station,\n",
    "#                           station_coords=station_coords,\n",
    "#                           cnn_out_dim=cnn_out_dim,\n",
    "#                           d_model=d_model,\n",
    "#                           num_station_transformer_layers=num_station_transformer_layers,\n",
    "#                           num_time_transformer_layers=num_time_transformer_layers,\n",
    "#                           num_heads=num_heads,\n",
    "#                           target_station_idx=target_station_idx,\n",
    "#                           label_width=label_width)\n",
    "\n",
    "# model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "# history = model.fit(window.train, epochs=10, validation_data=window.val)\n",
    "# model.evaluate(window.test)\n",
    "\n",
    "# Get predictions:\n",
    "# for inputs, labels in window.test.take(1):\n",
    "#     preds = model(inputs)\n",
    "#     print(\"Predictions shape:\", preds.shape)  # (batch, label_width, 1)\n",
    "#     print(\"Labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user imports\n",
    "import windowGenarator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Configuration\n",
    "#########################################\n",
    "\n",
    "num_stations = 5\n",
    "features_per_station = 12  # Example; adjust to actual feature count\n",
    "input_width = 24           # Example\n",
    "label_width = 1\n",
    "shift = 1\n",
    "label_columns = [\"TD (degC)\"]\n",
    "target_station_idx = 0\n",
    "\n",
    "# Model hyperparameters\n",
    "cnn_out_dim = 32\n",
    "d_model = 64\n",
    "num_heads = 4\n",
    "num_station_transformer_layers = 2\n",
    "num_time_transformer_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Load Data and Coordinates\n",
    "#########################################\n",
    "# Assume these DataFrames and station_coords are already loaded and preprocessed\n",
    "# train_df, val_df, test_df = ...\n",
    "# station_coords_df = pd.read_csv('stations_coords.csv')\n",
    "# Sort by station_id and extract coords in order\n",
    "# station_coords = station_coords_df[['x', 'y']].values.astype(np.float32)\n",
    "# Normalize coords if needed\n",
    "\n",
    "station_coords = np.array([\n",
    "    [350000, 3200000],\n",
    "    [351000, 3201000],\n",
    "    [352000, 3202000],\n",
    "    [353000, 3203000],\n",
    "    [354000, 3204000]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Optional: normalize coordinates\n",
    "# x_min, x_max = station_coords[:,0].min(), station_coords[:,0].max()\n",
    "# y_min, y_max = station_coords[:,1].min(), station_coords[:,1].max()\n",
    "# station_coords[:,0] = (station_coords[:,0] - x_min)/(x_max - x_min)\n",
    "# station_coords[:,1] = (station_coords[:,1] - y_min)/(y_max - y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# WindowGenerator (Given by you)\n",
    "#########################################\n",
    "# window = WindowGenerator(input_width=input_width,\n",
    "#                          label_width=label_width,\n",
    "#                          shift=shift,\n",
    "#                          train_df=train_df,\n",
    "#                          val_df=val_df,\n",
    "#                          test_df=test_df,\n",
    "#                          label_columns=label_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Model Components\n",
    "#########################################\n",
    "\n",
    "def make_station_cnn(features_per_station, cnn_out_dim):\n",
    "    \"\"\"\n",
    "    CNN that processes a single station's time series of shape (batch, input_width, features_per_station).\n",
    "    We'll keep the time dimension. The output shape: (batch, input_width, cnn_out_dim)\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv1D(filters=32, kernel_size=3, padding='causal', activation='relu', input_shape=(input_width, features_per_station)),\n",
    "        layers.Conv1D(filters=32, kernel_size=3, padding='causal', activation='relu'),\n",
    "        # No pooling here, we keep the time dimension\n",
    "        layers.Dense(cnn_out_dim)  # map to cnn_out_dim\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "class TransformerEncoderLayer(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = keras.Sequential([\n",
    "            layers.Dense(dff, activation='relu'),\n",
    "            layers.Dense(d_model),\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        # x: (batch, seq_len, d_model)\n",
    "        attn_output = self.mha(x, x, training=training)  # Self-attention\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.enc_layers = [TransformerEncoderLayer(d_model, num_heads, dff, dropout) for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training=training)\n",
    "        return x\n",
    "\n",
    "class MultiStationModel(keras.Model):\n",
    "    def __init__(self, \n",
    "                 num_stations, \n",
    "                 features_per_station,\n",
    "                 station_coords, \n",
    "                 cnn_out_dim,\n",
    "                 d_model,\n",
    "                 num_station_transformer_layers,\n",
    "                 num_time_transformer_layers,\n",
    "                 num_heads,\n",
    "                 target_station_idx=0,\n",
    "                 label_width=1):\n",
    "        super().__init__()\n",
    "        self.num_stations = num_stations\n",
    "        self.features_per_station = features_per_station\n",
    "        self.target_station_idx = target_station_idx\n",
    "        self.label_width = label_width\n",
    "        self.station_coords = tf.constant(station_coords, dtype=tf.float32) # (num_stations, 2)\n",
    "\n",
    "        # A CNN for each station:\n",
    "        # We'll apply the same CNN weights to all stations (shared weights)\n",
    "        # If you need distinct CNNs per station, create a list of CNNs.\n",
    "        self.station_cnn = make_station_cnn(features_per_station, cnn_out_dim)\n",
    "\n",
    "        # Project CNN output + coords to d_model\n",
    "        self.project = layers.Dense(d_model)\n",
    "\n",
    "        # Transformer for station dimension\n",
    "        self.station_transformer = TransformerEncoder(num_station_transformer_layers, d_model, num_heads)\n",
    "\n",
    "        # Transformer for time dimension (long-term patterns)\n",
    "        self.time_transformer = TransformerEncoder(num_time_transformer_layers, d_model, num_heads)\n",
    "\n",
    "        # Final output layer\n",
    "        self.output_layer = layers.Dense(self.label_width)  # Predict 1 step (or label_width steps)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        # inputs: (batch, input_width, total_features)\n",
    "        # total_features = num_stations * features_per_station\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        total_features = self.num_stations * self.features_per_station\n",
    "        # Split the input for each station\n",
    "        # Shape: (batch, input_width, features_per_station) per station\n",
    "        station_embeddings_list = []\n",
    "        for i in range(self.num_stations):\n",
    "            start = i * self.features_per_station\n",
    "            end = start + self.features_per_station\n",
    "            station_data = inputs[:, :, start:end]  # (batch, input_width, features_per_station)\n",
    "            \n",
    "            # CNN to extract local patterns\n",
    "            station_cnn_out = self.station_cnn(station_data, training=training) # (batch, input_width, cnn_out_dim)\n",
    "            \n",
    "            # Add coordinates (x, y) to each time step\n",
    "            # coords shape: (1, 1, 2) expanded to (batch, input_width, 2)\n",
    "            coords = tf.reshape(self.station_coords[i], (1,1,2))\n",
    "            coords = tf.tile(coords, [batch_size, tf.shape(station_cnn_out)[1], 1]) # (batch, input_width, 2)\n",
    "            \n",
    "            # Concatenate coords\n",
    "            combined = tf.concat([station_cnn_out, coords], axis=-1) # (batch, input_width, cnn_out_dim+2)\n",
    "            \n",
    "            # Project to d_model\n",
    "            projected = self.project(combined, training=training) # (batch, input_width, d_model)\n",
    "            station_embeddings_list.append(projected)\n",
    "\n",
    "        # Now we have a list of station embeddings: each (batch, input_width, d_model)\n",
    "        # Stack them to form (batch, input_width, num_stations, d_model)\n",
    "        station_embeddings = tf.stack(station_embeddings_list, axis=2) # (batch, input_width, num_stations, d_model)\n",
    "\n",
    "        # First Transformer: Station dimension\n",
    "        # We want to understand station relationships at each time step.\n",
    "        # So for each time step t, we have (batch, num_stations, d_model).\n",
    "        # We'll flatten batch and time steps to process them at once:\n",
    "        \n",
    "        B = batch_size\n",
    "        T = input_width\n",
    "        S = self.num_stations\n",
    "\n",
    "        # Reshape to (B*T, S, d_model)\n",
    "        station_embeddings_reshaped = tf.reshape(station_embeddings, (B*T, S, d_model))\n",
    "        \n",
    "        # Pass through station-transformer\n",
    "        station_transformed = self.station_transformer(station_embeddings_reshaped, training=training) # (B*T, S, d_model)\n",
    "\n",
    "        # Extract target station embedding: (B*T, d_model)\n",
    "        target_embeddings = station_transformed[:, self.target_station_idx, :] # (B*T, d_model)\n",
    "\n",
    "        # Reshape back to (B, T, d_model)\n",
    "        target_time_series = tf.reshape(target_embeddings, (B, T, d_model))\n",
    "\n",
    "        # Second Transformer: Time dimension\n",
    "        # Now we model long-term temporal patterns of the target station embedding sequence.\n",
    "        # Shape: (batch, input_width, d_model)\n",
    "        time_transformed = self.time_transformer(target_time_series, training=training) # (batch, input_width, d_model)\n",
    "\n",
    "        # Predict temperature at the forecast horizon\n",
    "        # Assume we want the last time step embedding for prediction, or entire sequence if label_width > 1\n",
    "        # Since label_width=1, we take the last time step (e.g. final embedding)\n",
    "        final_embedding = time_transformed[:, -1, :] # (batch, d_model)\n",
    "        \n",
    "        predictions = self.output_layer(final_embedding) # (batch, label_width)\n",
    "        # Expand dims to (batch, label_width, 1) if needed\n",
    "        predictions = tf.expand_dims(predictions, -1) # (batch, label_width, 1)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Training Example\n",
    "#########################################\n",
    "\n",
    "# Example usage (uncomment and adjust once you have train/val/test data):\n",
    "# model = MultiStationModel(num_stations=num_stations,\n",
    "#                           features_per_station=features_per_station,\n",
    "#                           station_coords=station_coords,\n",
    "#                           cnn_out_dim=cnn_out_dim,\n",
    "#                           d_model=d_model,\n",
    "#                           num_station_transformer_layers=num_station_transformer_layers,\n",
    "#                           num_time_transformer_layers=num_time_transformer_layers,\n",
    "#                           num_heads=num_heads,\n",
    "#                           target_station_idx=target_station_idx,\n",
    "#                           label_width=label_width)\n",
    "\n",
    "# model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "# history = model.fit(window.train, epochs=10, validation_data=window.val)\n",
    "# model.evaluate(window.test)\n",
    "\n",
    "# Get predictions:\n",
    "# for inputs, labels in window.test.take(1):\n",
    "#     preds = model(inputs)\n",
    "#     print(\"Predictions shape:\", preds.shape)  # (batch, label_width, 1)\n",
    "#     print(\"Labels shape:\", labels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
